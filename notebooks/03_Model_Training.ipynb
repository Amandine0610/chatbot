{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Healthcare Chatbot - Model Training\n",
    "\n",
    "In this notebook, you'll:\n",
    "1. Set up training configuration\n",
    "2. Choose and load a pre-trained model\n",
    "3. Train your healthcare chatbot\n",
    "4. Monitor training progress\n",
    "5. Save and test your trained model\n",
    "\n",
    "Let's train your AI doctor! ü§ñüè•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 1: Training Configuration\n",
    "\n",
    "First, let's set up the training parameters and check our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('/workspace/src')\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üîß Training environment setup complete!\")\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üéÆ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"üíª Using CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration - MODIFY THESE SETTINGS\n",
    "TRAINING_CONFIG = {\n",
    "    # Dataset settings\n",
    "    'dataset_path': '/workspace/data/kaggle_medical_dataset.json',  # Path to your processed dataset\n",
    "    'max_samples': None,  # Limit dataset size (None = use all data)\n",
    "    'train_split': 0.8,   # Fraction for training vs validation\n",
    "    \n",
    "    # Model settings\n",
    "    'model_key': 'distilgpt2',  # Choose: distilgpt2, gpt2, dialogpt-medium\n",
    "    'output_dir': '/workspace/models/my_healthcare_chatbot',\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'epochs': 2,          # Number of training epochs (start with 1-2 for testing)\n",
    "    'batch_size': 2,      # Training batch size (reduce if out of memory)\n",
    "    'learning_rate': 5e-5, # Learning rate\n",
    "    'warmup_steps': 50,   # Warmup steps\n",
    "    \n",
    "    # Training options\n",
    "    'skip_hyperparameter_search': True,  # Set to False for automatic optimization\n",
    "    'use_early_stopping': True,\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
    "print(\"=\"*40)\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nüí° TIPS:\")\n",
    "print(\"- Start with distilgpt2 for quick testing\")\n",
    "print(\"- Use dialogpt-medium for better quality (slower)\")\n",
    "print(\"- Reduce batch_size if you get memory errors\")\n",
    "print(\"- Start with 1-2 epochs for testing, then increase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset availability\n",
    "dataset_path = TRAINING_CONFIG['dataset_path']\n",
    "\n",
    "print(\"üìä CHECKING DATASET\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    # Load and check dataset\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Dataset found: {dataset_path}\")\n",
    "    print(f\"üìä Total samples: {len(dataset)}\")\n",
    "    \n",
    "    # Apply sample limit if specified\n",
    "    if TRAINING_CONFIG['max_samples'] and len(dataset) > TRAINING_CONFIG['max_samples']:\n",
    "        dataset = dataset[:TRAINING_CONFIG['max_samples']]\n",
    "        print(f\"üìä Limited to: {len(dataset)} samples\")\n",
    "    \n",
    "    # Show sample\n",
    "    if dataset:\n",
    "        sample = dataset[0]\n",
    "        print(f\"\\nüìù Sample Q&A:\")\n",
    "        print(f\"   Q: {sample['question']}\")\n",
    "        print(f\"   A: {sample['answer'][:100]}...\")\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    train_size = int(len(dataset) * TRAINING_CONFIG['train_split'])\n",
    "    val_size = len(dataset) - train_size\n",
    "    \n",
    "    print(f\"\\nüìà Training split:\")\n",
    "    print(f\"   Training: {train_size} samples ({TRAINING_CONFIG['train_split']*100:.0f}%)\")\n",
    "    print(f\"   Validation: {val_size} samples ({(1-TRAINING_CONFIG['train_split'])*100:.0f}%)\")\n",
    "    \n",
    "    dataset_ready = True\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found: {dataset_path}\")\n",
    "    print(\"\\nüîß SOLUTIONS:\")\n",
    "    print(\"1. Run notebook 02_Data_Exploration.ipynb first\")\n",
    "    print(\"2. Or run: python setup_kaggle_dataset.py\")\n",
    "    print(\"3. Check that your dataset path is correct\")\n",
    "    \n",
    "    dataset_ready = False\n",
    "    dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 2: Model Selection and Setup\n",
    "\n",
    "Let's load and configure the pre-trained model for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model information\n",
    "MODEL_INFO = {\n",
    "    'distilgpt2': {\n",
    "        'description': 'Lightweight GPT-2 variant (fastest)',\n",
    "        'size': '~350MB',\n",
    "        'speed': 'Fast',\n",
    "        'quality': 'Good',\n",
    "        'recommended_for': 'Testing, small datasets, quick experiments'\n",
    "    },\n",
    "    'gpt2': {\n",
    "        'description': 'Original GPT-2 base model',\n",
    "        'size': '~500MB',\n",
    "        'speed': 'Medium',\n",
    "        'quality': 'Good',\n",
    "        'recommended_for': 'Balanced performance and speed'\n",
    "    },\n",
    "    'dialogpt-medium': {\n",
    "        'description': 'Microsoft DialoGPT optimized for conversation',\n",
    "        'size': '~1.5GB',\n",
    "        'speed': 'Slower',\n",
    "        'quality': 'Best',\n",
    "        'recommended_for': 'Production use, best conversational quality'\n",
    "    }\n",
    "}\n",
    "\n",
    "selected_model = TRAINING_CONFIG['model_key']\n",
    "\n",
    "print(\"ü§ñ MODEL SELECTION\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Selected model: {selected_model}\")\n",
    "\n",
    "if selected_model in MODEL_INFO:\n",
    "    info = MODEL_INFO[selected_model]\n",
    "    print(f\"\\nüìã Model Information:\")\n",
    "    for key, value in info.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Unknown model: {selected_model}\")\n",
    "\n",
    "print(\"\\nüîÑ Available Models:\")\n",
    "for model, info in MODEL_INFO.items():\n",
    "    icon = \"üëâ\" if model == selected_model else \"  \"\n",
    "    print(f\"{icon} {model}: {info['description']} ({info['size']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model manager and load model\n",
    "if dataset_ready:\n",
    "    print(\"üîÑ LOADING MODEL\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    try:\n",
    "        from model_manager import HealthcareModelManager\n",
    "        \n",
    "        # Initialize model manager\n",
    "        model_manager = HealthcareModelManager(\n",
    "            model_key=TRAINING_CONFIG['model_key'],\n",
    "            device='auto'  # Automatically choose GPU or CPU\n",
    "        )\n",
    "        \n",
    "        print(f\"üîÑ Loading {TRAINING_CONFIG['model_key']}...\")\n",
    "        print(\"   (This may take a few minutes for first download)\")\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        model, tokenizer = model_manager.load_model_and_tokenizer()\n",
    "        \n",
    "        print(\"‚úÖ Model loaded successfully!\")\n",
    "        \n",
    "        # Get model information\n",
    "        model_info = model_manager.get_model_info()\n",
    "        \n",
    "        print(f\"\\nüìä Model Details:\")\n",
    "        for key, value in model_info.items():\n",
    "            if key != 'model_key':\n",
    "                print(f\"   {key}: {value}\")\n",
    "        \n",
    "        model_loaded = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {e}\")\n",
    "        print(\"\\nüîß SOLUTIONS:\")\n",
    "        print(\"1. Check internet connection (for model download)\")\n",
    "        print(\"2. Try a smaller model (distilgpt2)\")\n",
    "        print(\"3. Restart the notebook if memory issues\")\n",
    "        \n",
    "        model_loaded = False\n",
    "        model_manager = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot load model - dataset not ready\")\n",
    "    model_loaded = False\n",
    "    model_manager = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Step 3: Training Setup and Execution\n",
    "\n",
    "Now let's set up the training pipeline and start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fine-tuner\n",
    "if dataset_ready and model_loaded:\n",
    "    print(\"üéì SETTING UP TRAINING\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    try:\n",
    "        from fine_tuning import HealthcareFinetuner\n",
    "        \n",
    "        # Initialize fine-tuner\n",
    "        finetuner = HealthcareFinetuner(\n",
    "            model_key=TRAINING_CONFIG['model_key'],\n",
    "            output_dir=TRAINING_CONFIG['output_dir']\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Fine-tuner initialized\")\n",
    "        \n",
    "        # Prepare dataset\n",
    "        print(\"üîÑ Preparing dataset...\")\n",
    "        training_dataset = finetuner.prepare_data(\n",
    "            dataset_path=TRAINING_CONFIG['dataset_path'],\n",
    "            train_split=TRAINING_CONFIG['train_split']\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Dataset prepared:\")\n",
    "        print(f\"   Training samples: {len(training_dataset['train'])}\")\n",
    "        print(f\"   Validation samples: {len(training_dataset['validation'])}\")\n",
    "        \n",
    "        training_ready = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error setting up training: {e}\")\n",
    "        training_ready = False\n",
    "        finetuner = None\n",
    "        training_dataset = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot set up training - prerequisites not met\")\n",
    "    training_ready = False\n",
    "    finetuner = None\n",
    "    training_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate training time\n",
    "if training_ready:\n",
    "    print(\"‚è±Ô∏è TRAINING TIME ESTIMATION\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Rough estimates based on model and data size\n",
    "    train_samples = len(training_dataset['train'])\n",
    "    epochs = TRAINING_CONFIG['epochs']\n",
    "    batch_size = TRAINING_CONFIG['batch_size']\n",
    "    \n",
    "    # Calculate steps\n",
    "    steps_per_epoch = train_samples // batch_size\n",
    "    total_steps = steps_per_epoch * epochs\n",
    "    \n",
    "    # Time estimates (very rough)\n",
    "    if TRAINING_CONFIG['model_key'] == 'distilgpt2':\n",
    "        seconds_per_step = 2 if torch.cuda.is_available() else 8\n",
    "    elif TRAINING_CONFIG['model_key'] == 'gpt2':\n",
    "        seconds_per_step = 3 if torch.cuda.is_available() else 12\n",
    "    else:  # dialogpt-medium\n",
    "        seconds_per_step = 5 if torch.cuda.is_available() else 20\n",
    "    \n",
    "    estimated_seconds = total_steps * seconds_per_step\n",
    "    estimated_minutes = estimated_seconds / 60\n",
    "    \n",
    "    print(f\"üìä Training Overview:\")\n",
    "    print(f\"   Samples: {train_samples}\")\n",
    "    print(f\"   Epochs: {epochs}\")\n",
    "    print(f\"   Batch size: {batch_size}\")\n",
    "    print(f\"   Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"   Total steps: {total_steps}\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Estimated training time: {estimated_minutes:.1f} minutes\")\n",
    "    \n",
    "    if estimated_minutes > 30:\n",
    "        print(\"\\n‚ö†Ô∏è Training will take a while. Consider:\")\n",
    "        print(\"   - Reducing epochs or max_samples\")\n",
    "        print(\"   - Using a smaller model (distilgpt2)\")\n",
    "        print(\"   - Increasing batch_size if you have GPU memory\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Ready to start training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START TRAINING!\n",
    "if training_ready:\n",
    "    print(\"üöÄ STARTING TRAINING\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"‚è∞ Start time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(\"\\nüîÑ Training in progress...\")\n",
    "    print(\"   (This cell will show progress updates)\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare hyperparameters\n",
    "        if TRAINING_CONFIG['skip_hyperparameter_search']:\n",
    "            hyperparameters = {\n",
    "                'learning_rate': TRAINING_CONFIG['learning_rate'],\n",
    "                'per_device_train_batch_size': TRAINING_CONFIG['batch_size'],\n",
    "                'num_train_epochs': TRAINING_CONFIG['epochs'],\n",
    "                'warmup_steps': TRAINING_CONFIG['warmup_steps']\n",
    "            }\n",
    "            print(f\"üìã Using manual hyperparameters: {hyperparameters}\")\n",
    "        else:\n",
    "            hyperparameters = None\n",
    "            print(\"üîç Will perform hyperparameter search...\")\n",
    "        \n",
    "        # Start training\n",
    "        start_time = time.time()\n",
    "        \n",
    "        training_results = finetuner.fine_tune(\n",
    "            dataset=training_dataset,\n",
    "            hyperparameters=hyperparameters,\n",
    "            use_early_stopping=TRAINING_CONFIG['use_early_stopping']\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        \n",
    "        print(\"\\nüéâ TRAINING COMPLETED!\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"‚è∞ Training time: {training_time/60:.1f} minutes\")\n",
    "        print(f\"üìä Final training loss: {training_results.get('train_loss', 'N/A'):.4f}\")\n",
    "        print(f\"üìä Final validation loss: {training_results.get('eval_loss', 'N/A'):.4f}\")\n",
    "        print(f\"üíæ Model saved to: {training_results['model_path']}\")\n",
    "        \n",
    "        training_completed = True\n",
    "        model_path = training_results['model_path']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Training failed: {e}\")\n",
    "        print(\"\\nüîß TROUBLESHOOTING:\")\n",
    "        print(\"1. Check GPU memory (reduce batch_size)\")\n",
    "        print(\"2. Try a smaller model (distilgpt2)\")\n",
    "        print(\"3. Reduce max_samples or epochs\")\n",
    "        print(\"4. Restart notebook to free memory\")\n",
    "        \n",
    "        training_completed = False\n",
    "        model_path = None\n",
    "        training_results = None\n",
    "        \n",
    "        # Print full error for debugging\n",
    "        import traceback\n",
    "        print(f\"\\nüêõ Full error:\\n{traceback.format_exc()}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot start training - setup incomplete\")\n",
    "    training_completed = False\n",
    "    model_path = None\n",
    "    training_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: Training Results Analysis\n",
    "\n",
    "Let's analyze the training results and visualize the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training results\n",
    "if training_completed and training_results:\n",
    "    print(\"üìä TRAINING RESULTS ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Display key metrics\n",
    "    results_summary = {\n",
    "        'Final Training Loss': f\"{training_results.get('train_loss', 'N/A'):.4f}\",\n",
    "        'Final Validation Loss': f\"{training_results.get('eval_loss', 'N/A'):.4f}\",\n",
    "        'Training Runtime': f\"{training_results.get('train_runtime', 0)/60:.1f} minutes\",\n",
    "        'Model Path': training_results.get('model_path', 'N/A'),\n",
    "        'Hyperparameters': training_results.get('hyperparameters', {})\n",
    "    }\n",
    "    \n",
    "    for key, value in results_summary.items():\n",
    "        if key == 'Hyperparameters':\n",
    "            print(f\"{key}:\")\n",
    "            for hp_key, hp_value in value.items():\n",
    "                print(f\"   {hp_key}: {hp_value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Plot training curves if available\n",
    "    training_history = training_results.get('training_history', [])\n",
    "    \n",
    "    if training_history:\n",
    "        print(\"\\nüìà Plotting training curves...\")\n",
    "        \n",
    "        # Extract losses\n",
    "        train_logs = [log for log in training_history if 'loss' in log]\n",
    "        eval_logs = [log for log in training_history if 'eval_loss' in log]\n",
    "        \n",
    "        if train_logs and eval_logs:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "            \n",
    "            # Training and validation loss\n",
    "            train_steps = [log['step'] for log in train_logs]\n",
    "            train_losses = [log['loss'] for log in train_logs]\n",
    "            eval_steps = [log['step'] for log in eval_logs]\n",
    "            eval_losses = [log['eval_loss'] for log in eval_logs]\n",
    "            \n",
    "            ax1.plot(train_steps, train_losses, label='Training Loss', alpha=0.7)\n",
    "            ax1.plot(eval_steps, eval_losses, label='Validation Loss', alpha=0.7)\n",
    "            ax1.set_xlabel('Steps')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Training Progress')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Learning rate schedule\n",
    "            lr_logs = [log for log in training_history if 'learning_rate' in log]\n",
    "            if lr_logs:\n",
    "                lr_steps = [log['step'] for log in lr_logs]\n",
    "                lr_values = [log['learning_rate'] for log in lr_logs]\n",
    "                ax2.plot(lr_steps, lr_values, label='Learning Rate', color='orange')\n",
    "                ax2.set_xlabel('Steps')\n",
    "                ax2.set_ylabel('Learning Rate')\n",
    "                ax2.set_title('Learning Rate Schedule')\n",
    "                ax2.legend()\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "            else:\n",
    "                ax2.text(0.5, 0.5, 'No learning rate data\\navailable', \n",
    "                         ha='center', va='center', transform=ax2.transAxes)\n",
    "                ax2.set_title('Learning Rate Schedule')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No training curves available to plot\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No training history available\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 5: Quick Model Testing\n",
    "\n",
    "Let's test our trained model with some sample questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "if training_completed and model_path:\n",
    "    print(\"üß™ TESTING TRAINED MODEL\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    try:\n",
    "        from chatbot import HealthcareChatbot\n",
    "        \n",
    "        # Initialize chatbot with trained model\n",
    "        print(\"üîÑ Loading trained model for testing...\")\n",
    "        chatbot = HealthcareChatbot(model_path)\n",
    "        \n",
    "        print(\"‚úÖ Chatbot initialized!\")\n",
    "        \n",
    "        # Test questions\n",
    "        test_questions = [\n",
    "            \"What are the symptoms of diabetes?\",\n",
    "            \"How can I prevent heart disease?\",\n",
    "            \"What should I do if I have a fever?\",\n",
    "            \"How much water should I drink daily?\",\n",
    "            \"What are the side effects of aspirin?\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nü§ñ CHATBOT RESPONSES:\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        for i, question in enumerate(test_questions, 1):\n",
    "            print(f\"\\n{i}. üë§ User: {question}\")\n",
    "            \n",
    "            try:\n",
    "                response = chatbot.chat(question)\n",
    "                print(f\"   üè• Bot: {response['response']}\")\n",
    "                print(f\"   üìä Type: {response['type']}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error: {e}\")\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        print(\"\\n‚úÖ Model testing completed!\")\n",
    "        testing_completed = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing model: {e}\")\n",
    "        print(\"\\nüîß TROUBLESHOOTING:\")\n",
    "        print(\"1. Make sure training completed successfully\")\n",
    "        print(\"2. Check that model files were saved properly\")\n",
    "        print(\"3. Try restarting the notebook\")\n",
    "        \n",
    "        testing_completed = False\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot test model - training not completed\")\n",
    "    testing_completed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 6: Next Steps\n",
    "\n",
    "Congratulations! You've trained your healthcare chatbot. Here's what to do next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ TRAINING SESSION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if training_completed:\n",
    "    print(f\"‚úÖ Successfully trained healthcare chatbot!\")\n",
    "    print(f\"üíæ Model saved to: {model_path}\")\n",
    "    \n",
    "    if training_results:\n",
    "        print(f\"üìä Final validation loss: {training_results.get('eval_loss', 'N/A'):.4f}\")\n",
    "        print(f\"‚è±Ô∏è Training time: {training_results.get('train_runtime', 0)/60:.1f} minutes\")\n",
    "    \n",
    "    print(\"\\nüöÄ NEXT STEPS:\")\n",
    "    print(\"-\"*20)\n",
    "    \n",
    "    print(\"1. üìà Evaluate Your Model:\")\n",
    "    print(\"   ‚Üí Open: notebooks/04_Model_Evaluation.ipynb\")\n",
    "    print(\"   ‚Üí Get detailed performance metrics\")\n",
    "    \n",
    "    print(\"\\n2. üåê Deploy Your Chatbot:\")\n",
    "    print(\"   ‚Üí Open: notebooks/05_Deployment.ipynb\")\n",
    "    print(\"   ‚Üí Launch web interface\")\n",
    "    \n",
    "    print(\"\\n3. üñ•Ô∏è Quick Testing Options:\")\n",
    "    print(f\"   ‚Üí CLI: python -m src.chatbot {model_path}\")\n",
    "    print(f\"   ‚Üí Web: python -m src.web_interface --model_path {model_path}\")\n",
    "    \n",
    "    print(\"\\n4. üîß Model Improvement Ideas:\")\n",
    "    if training_results and training_results.get('eval_loss', 0) > 2.0:\n",
    "        print(\"   ‚Üí Try more epochs (increase from current)\")\n",
    "        print(\"   ‚Üí Use a larger model (dialogpt-medium)\")\n",
    "        print(\"   ‚Üí Add more training data\")\n",
    "    else:\n",
    "        print(\"   ‚Üí Your model looks good!\")\n",
    "        print(\"   ‚Üí Consider fine-tuning hyperparameters\")\n",
    "        print(\"   ‚Üí Test with more diverse questions\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Training was not completed successfully.\")\n",
    "    print(\"\\nüîß TROUBLESHOOTING STEPS:\")\n",
    "    print(\"-\"*25)\n",
    "    print(\"1. Check error messages above\")\n",
    "    print(\"2. Try reducing batch_size or epochs\")\n",
    "    print(\"3. Use a smaller model (distilgpt2)\")\n",
    "    print(\"4. Restart notebook and try again\")\n",
    "    print(\"5. Check dataset format and size\")\n",
    "\n",
    "print(\"\\nüìö RESOURCES:\")\n",
    "print(\"-\"*15)\n",
    "print(\"‚Ä¢ Training Guide: KAGGLE_DATASET_GUIDE.md\")\n",
    "print(\"‚Ä¢ Quick Commands: YOUR_KAGGLE_DATASET_INSTRUCTIONS.md\")\n",
    "print(\"‚Ä¢ Next Notebook: 04_Model_Evaluation.ipynb\")\n",
    "print(\"‚Ä¢ Deployment: 05_Deployment.ipynb\")\n",
    "\n",
    "print(\"\\nüí° TIP: Save this notebook to preserve your training configuration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training summary for reference\n",
    "if training_completed and training_results:\n",
    "    summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'config': TRAINING_CONFIG,\n",
    "        'results': {\n",
    "            'model_path': model_path,\n",
    "            'train_loss': training_results.get('train_loss'),\n",
    "            'eval_loss': training_results.get('eval_loss'),\n",
    "            'train_runtime': training_results.get('train_runtime'),\n",
    "        },\n",
    "        'model_info': model_info if 'model_info' in locals() else {},\n",
    "        'testing_completed': testing_completed if 'testing_completed' in locals() else False\n",
    "    }\n",
    "    \n",
    "    summary_path = '/workspace/notebooks/training_session_summary.json'\n",
    "    \n",
    "    try:\n",
    "        with open(summary_path, 'w') as f:\n",
    "            json.dump(summary, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"üíæ Training summary saved to: {summary_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save summary: {e}\")\n",
    "\n",
    "print(\"\\nüéä Ready for the next step in your AI journey!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}